{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotnine as gg\n",
    "import scipy\n",
    "gg.theme_set(gg.theme_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_param_dir = 'C:/Users/maria/MEGAsync/SLCN/PShumanData/fitting/mice/'\n",
    "plot_dir = 'C:/Users/maria/MEGAsync/SLCN/models/plots'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fitted params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params = pd.DataFrame()\n",
    "modelnames = [f for f in os.listdir(fitted_param_dir) if ('.csv' in f) and ('params' in f)]\n",
    "for modelname in modelnames:\n",
    "    model_params = pd.read_csv(os.path.join(fitted_param_dir, modelname))\n",
    "    model_params['model'] = modelname.split('_')[1]\n",
    "    fitted_params = fitted_params.append(model_params, sort=False)\n",
    "fitted_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params_ = fitted_params.copy()\n",
    "fitted_params_['beta'] /= 20\n",
    "fitted_params_long = fitted_params_.melt(\n",
    "    id_vars=['sID', 'slope_variable', 'fullID', 'animal', 'PreciseYrs', 'Gender', 'treatment',\n",
    "             'session', 'age_z', 'T1', 'PDS', 'model'],\n",
    "    value_name='param_value', var_name='param'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (gg.ggplot(fitted_params_long, gg.aes('param', 'param_value'))\n",
    " + gg.stat_summary(geom='bar')\n",
    " + gg.geom_point(position='jitter', alpha=0.2)\n",
    " + gg.facet_wrap('~ model')\n",
    ")\n",
    "g.draw()\n",
    "g.save(os.path.join(plot_dir, 'fitted_params.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.DataFrame({\n",
    "    'alpha': [0.8], 'nalpha': [0.1], 'calpha': [0.9], 'cnalpha': [0.1],\n",
    "    'beta': [4], 'persev': [0.2], 'bias': [0]\n",
    "})\n",
    "init_Q = 1/2\n",
    "n_agents = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PSAgent():\n",
    "    \n",
    "    def __init__(self, n_agents, params, init_Q, eps=1e-5):\n",
    "        self.n_agents = n_agents\n",
    "        self.params = params\n",
    "        self.avail_actions = (0, 1)\n",
    "        self.init_Q = init_Q\n",
    "        self.Q = init_Q * np.ones((n_agents, len(self.avail_actions)))\n",
    "        self.eps = eps\n",
    "        self.prev_action = np.full(n_agents, np.nan)\n",
    "        \n",
    "    def take_action(self):\n",
    "        \"\"\"\n",
    "        Take 1 action per agent, based on current trial Q-values.\n",
    "        \"\"\"\n",
    "        \n",
    "        ags = np.arange(self.n_agents)\n",
    "\n",
    "        # Perseveration\n",
    "        Q0 = self.Q[ags, 0]\n",
    "        Q1 = self.Q[ags, 1]\n",
    "        if not np.isnan(self.prev_action[0]):  # prev_action is np.nan on trial 0 only; only checking first element for simplicity\n",
    "            Q0 += (1 - self.prev_action) * self.params['persev'].values  # action 0: subtract persev when repeating\n",
    "            Q1 += self.prev_action * self.params['persev'].values   # action 1: add persev when repeating\n",
    "\n",
    "        # Action selection\n",
    "        lik = scipy.special.softmax(self.params['beta'].values * np.array([Q0, Q1]).T, axis=1)\n",
    "        action = np.array([np.random.choice(self.avail_actions, p=lik[a]) for a in range(self.n_agents)])\n",
    "        self.prev_action = action.copy()\n",
    "        \n",
    "#         lik = self.eps / 2 + (1 - self.eps) + lik  # squeeze between eps and 1-eps to avoid 0's and 1's\n",
    "        \n",
    "        return lik, action\n",
    "    \n",
    "    def update_Q(self, action, reward):\n",
    "        \"\"\"\n",
    "        Update Q-values based on RL.\n",
    "        \"\"\"\n",
    "        \n",
    "        ags = np.arange(self.n_agents)\n",
    "        \n",
    "        rpe = (1 - self.Q[ags, action]) * reward  # received reward, updating chosen action\n",
    "        nrpe = (0 - self.Q[ags, action]) * (1 - reward)  # received no reward, updating chosen action\n",
    "        \n",
    "        crpe = (0 - self.Q[ags, 1-action]) * reward  # received reward, updating unchosen action\n",
    "        cnrpe = (1 - self.Q[ags, 1-action]) * (1 - reward)  # received no reard, updating unchosen action\n",
    "        \n",
    "        self.Q[ags, action] += self.params['alpha'].values * rpe + self.params['nalpha'].values * nrpe\n",
    "        self.Q[ags, 1-action] += self.params['calpha'].values * crpe + self.params['cnalpha'].values * cnrpe\n",
    "\n",
    "\n",
    "# Example use:\n",
    "agent = PSAgent(n_agents, params, init_Q)\n",
    "lik, action = agent.take_action()\n",
    "print(\"action\", action)\n",
    "correct, reward = task.present_reward(action, trial)\n",
    "print(\"reward\", reward)\n",
    "agent.update_Q(action, reward)\n",
    "print(\"agent.Q\", agent.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 200\n",
    "p_cor = 0.75\n",
    "block_lengths_lower = 40\n",
    "block_lengths_upper = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSTask():\n",
    "    \n",
    "    def __init__(self, p_cor, correct_actions, n_trials, block_lengths_lower, block_lengths_upper):\n",
    "        \"\"\"\n",
    "        Must either provide block_lengths_lower and block_lengths_upper -> task will be created on the fly;\n",
    "        or correct_actions -> provided task will be used.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.p_cor = p_cor\n",
    "\n",
    "        if len(correct_actions) > 0:\n",
    "            self.correct_actions = correct_actions\n",
    "            self.n_trials = len(correct_actions)\n",
    "        elif block_lengths_lower: \n",
    "            self.block_lengths_lower = block_lengths_lower\n",
    "            self.block_lengths_upper = block_lengths_upper\n",
    "            self.n_trials = n_trials\n",
    "            self.correct_actions = self.make_task()\n",
    "        else:\n",
    "            raise ValueError(\"You must provide either correct_actions or block_lengths_lower.\")\n",
    "        \n",
    "    def make_task(self):\n",
    "        \"\"\"\n",
    "        Currently just produces the same sequence of correct and incorrect boxes for each animal.\n",
    "        In future, will read in animal data.\n",
    "        \"\"\"\n",
    "        \n",
    "        correct_actions = []\n",
    "        block_lengths = np.random.randint(\n",
    "            low=self.block_lengths_lower, high=self.block_lengths_upper, size=self.n_trials)\n",
    "\n",
    "        for block_length, correct_side in zip(block_lengths, [0, 1] * self.n_trials):\n",
    "            correct_actions += block_length * [correct_side]\n",
    "        \n",
    "        correct_actions = correct_actions[:self.n_trials]\n",
    "        \n",
    "        return correct_actions\n",
    "        \n",
    "    def get_chance_rewards(self, n_correct_choices):\n",
    "        \"\"\"\n",
    "        Translate accuracy into rewards:\n",
    "        Return '1' with probability self.p_cor and '0' with probability 1-self.p_cor, for each agent.\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.array([np.random.choice((0, 1), p=(1-self.p_cor, self.p_cor)) for i in range(n_correct_choices)])\n",
    "\n",
    "    def present_reward(self, action, trial):\n",
    "        \"\"\"\n",
    "        Present reward (0, 1) for each agent in this trial, based on choices,\n",
    "        by consulting the correct_box on the current trial.\n",
    "        \"\"\"\n",
    "        \n",
    "        correct = np.array(self.correct_actions[trial] == action).astype(int)\n",
    "        reward = correct.copy()\n",
    "        reward[reward == 1] = self.get_chance_rewards(sum(reward==1))\n",
    "        \n",
    "        return correct, reward\n",
    "    \n",
    "# Example use\n",
    "task = PSTask(\n",
    "    p_cor, n_trials=n_trials, block_lengths_lower=block_lengths_lower, block_lengths_upper=block_lengths_upper,\n",
    "    correct_actions=[])\n",
    "task.make_task()\n",
    "\n",
    "task.get_chance_rewards(n_correct_choices=100)\n",
    "\n",
    "action = np.zeros(n_agents)\n",
    "trial = 0\n",
    "task.present_reward(action, trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simulate_dataset(task_args, agent_args):\n",
    "    \n",
    "    actions = []\n",
    "    liks = []\n",
    "    rewards = []\n",
    "    corrects = []\n",
    "\n",
    "    # Get task and agent\n",
    "    task = PSTask(task_args['p_cor'], n_trials=task_args['n_trials'],\n",
    "                  block_lengths_lower=task_args['block_lengths_lower'], block_lengths_upper=task_args['block_lengths_upper'],\n",
    "                  correct_actions=task_args['correct_actions'])\n",
    "    agent = PSAgent(agent_args['n_agents'], agent_args['params'], agent_args['init_Q'])\n",
    "\n",
    "    # Play the game, save data\n",
    "    for trial in range(n_trials):\n",
    "\n",
    "        lik, action = agent.take_action()\n",
    "        correct, reward = task.present_reward(action, trial)\n",
    "        agent.update_Q(action, reward)\n",
    "\n",
    "        actions += [action]\n",
    "        liks += [lik]\n",
    "        rewards += [reward]\n",
    "        corrects += [correct]\n",
    "\n",
    "    # Format data\n",
    "    data = pd.DataFrame(\n",
    "            {'action': actions, 'lik': liks,\n",
    "             'reward': rewards, 'correct': corrects, 'correct_action': task.correct_actions})\n",
    "    data = data.reset_index()\n",
    "    data = data.rename(columns={'index': 'trial'})\n",
    "\n",
    "    data['mean_reward'] = np.mean(np.array(list(data.reward)), axis=1)\n",
    "    data['mean_correct'] = np.mean(np.array(list(data.correct)), axis=1)\n",
    "    data['block'] = np.append([0], np.cumsum(np.abs(np.diff(task.correct_actions))))\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example use\n",
    "task_args = {\n",
    "    'p_cor': 0.75, 'correct_actions': [], 'n_trials': n_trials,\n",
    "    'block_lengths_lower': block_lengths_lower, 'block_lengths_upper': block_lengths_upper\n",
    "}\n",
    "agent_args = {\n",
    "    'n_agents': n_agents, 'params': params, 'init_Q': init_Q,\n",
    "}\n",
    "\n",
    "data = simulate_dataset(task_args, agent_args)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gg.ggplot(data, gg.aes('trial', 'mean_correct', color='block'))\n",
    " + gg.geom_point()\n",
    " + gg.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated mouse data from fitted params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['alpha', 'nalpha', 'calpha', 'cnalpha', 'beta', 'persev', 'bias']\n",
    "model_name = 'RLab'\n",
    "n_agents = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_names = [modelname.split('_')[1] for modelname in modelnames]\n",
    "for model_name in model_names:\n",
    "    print(model_name, model_names)\n",
    "    sim_data = pd.DataFrame()\n",
    "    \n",
    "    for animal, age in zip(animals, ages):\n",
    "        if (animal != 23) and (age != 43):  # Error in the Juvi_AnimalID.csv - rerunning fitted_params with fixed one\n",
    "\n",
    "            # Get task for this mouse\n",
    "            true_sub = true_dat.loc[(true_dat.age == age) & (true_dat.animal == animal)]\n",
    "            n_trials = len(np.unique(true_sub.trial))\n",
    "            correct_actions = true_sub.correct_action.values\n",
    "\n",
    "            # Get params\n",
    "            params = fitted_params.loc[\n",
    "                (fitted_params.PreciseYrs == age) & (fitted_params.animal == animal) & (fitted_params.model == model_name),\n",
    "                param_names]\n",
    "            task_args = {\n",
    "                'p_cor': 0.75, 'correct_actions': correct_actions, 'n_trials': 0,\n",
    "                'block_lengths_lower': False, 'block_lengths_upper': False\n",
    "            }\n",
    "            agent_args = {\n",
    "                'n_agents': n_agents, 'params': params, 'init_Q': init_Q\n",
    "            }\n",
    "\n",
    "            sub_data = simulate_dataset(task_args, agent_args)\n",
    "            sub_data['session'] = true_sub.session[0]\n",
    "            sub_data['animal'] = animal\n",
    "            sub_data['age'] = age\n",
    "            sub_data['model'] = model_name\n",
    "\n",
    "            sim_data = sim_data.append(sub_data)\n",
    "    \n",
    "    save_dir = os.path.join(fitted_param_dir, 'simulations/simulated_mice_{}_nagents{}.csv'.format(model_name, n_agents))\n",
    "    print(\"Saving sim_data ({}) to {}...\".format(sim_data.shape, save_dir))\n",
    "    sim_data.to_csv(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super basic check\n",
    "gg.options.figure_size = (10, 10)\n",
    "(gg.ggplot(sim_data, gg.aes('trial', 'mean_correct', color='block'))\n",
    " + gg.stat_summary()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "* Simulate all mice, all sessions, based on fitted parameters\n",
    "* Save as csvs\n",
    "* Option A) Read into R and analyze in the same way as humans\n",
    "* Option B) Reimplement the analyses in python and analyze there\n",
    "* Bring actual mouse data into the dame shape and analyze in the same way\n",
    "* Compare models\n",
    "* Average over mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYMC3",
   "language": "python",
   "name": "pymc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
