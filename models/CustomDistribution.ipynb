{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data: 4 trials, 2 actions\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([0, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    T.printing.Print('rand')(np.random.rand())\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    \n",
    "    # Trial 1\n",
    "    Q_low0 = 0.5 * T.ones([n_aliens, n_actions])  # initialize Q-values for all trials, aliens, & actions to 0.5\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    RPE = rewards[0] - Q_low0[aliens[0], actions[0]]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "    Q_low1 = T.set_subtensor(Q_low0[aliens[0], actions[0]],\n",
    "                             Q_low0[aliens[0], actions[0]] + alpha * RPE)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 2\n",
    "    RPE = rewards[1] - Q_low1[aliens[1], actions[1]]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "    Q_low2 = T.set_subtensor(Q_low1[aliens[1], actions[1]],\n",
    "                             Q_low1[aliens[1], actions[1]] + alpha * RPE)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "    \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low2[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low = T.nnet.softmax(beta * Q_low_all)\n",
    "    T.printing.Print('p_low')(p_low)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple TS agent with argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n",
      "TS0 __str__ = 0\n",
      "Q_low0_sub __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = -0.5\n",
      "RPE_low __str__ = -0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]\n",
      " [0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "p_low __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]\n",
      " [0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "# Data: 4 trials, 2 actions\n",
    "seasons = np.array([0, 0, 0, 0])\n",
    "aliens = np.array([0, 0, 1, 1])\n",
    "actions = np.array([0, 1, 0, 1])\n",
    "rewards = np.array([0, 1, 0, 1])\n",
    "\n",
    "n_trials = 4\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Get Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    ## Select TS\n",
    "    TS0 = T.argmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Select action based on TS\n",
    "    Q_low0_sub = Q_low0[TS0]\n",
    "    p_low0 = T.nnet.softmax(Q_low0_sub)\n",
    "    T.printing.Print('Q_low0_sub')(Q_low0_sub)\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs and update Q-values\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE)\n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "#     # Trial 2\n",
    "#     RPE = rewards[1] - Q_low1[aliens[1], actions[1]]  # calculate RPE of the first trial\n",
    "#     T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "#     Q_low2 = T.set_subtensor(Q_low1[aliens[1], actions[1]],\n",
    "#                              Q_low1[aliens[1], actions[1]] + alpha * RPE)\n",
    "#     T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "#     Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low2[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low1[aliens[0]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low = T.nnet.softmax(beta * Q_low_all)\n",
    "    T.printing.Print('p_low')(p_low)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple TS agent with custom softmax selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a __str__ = [0 1]\n",
      "p __str__ = [0.5 0.5]\n",
      "TS __str__ = [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Print{message='TS', attrs=('__str__',), global_fn=<function _print_fn at 0x000001519417A9D8>}.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "rs = RandomStreams()\n",
    "# theano.sandbox.rng_mrg.MRG_RandomStreams.choice(size=1, a=None, replace=True, p=None, ndim=None, dtype='int64', nstreams=None, **kwargs)\n",
    "\n",
    "a = T.arange(2)\n",
    "p = T.as_tensor_variable(np.array([0.5, 0.5]))\n",
    "T.printing.Print('a')(a)\n",
    "T.printing.Print('p')(p)\n",
    "TS = rs.choice(size=[1], a=a, p=p)\n",
    "T.printing.Print('TS')(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha __str__ = 0.5\n",
      "beta __str__ = 1.0\n",
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high0 __str__ = [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS0 __str__ = 0\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = 0.5\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high1 __str__ = [0.5621765 0.4378235]\n",
      "TS1 __str__ = 0\n",
      "p_low1 __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n",
      "RPE_high __str__ = 0.25\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high2 __str__ = [[0.875 0.5  ]\n",
      " [0.5   0.5  ]]\n",
      "Q_low2 __str__ = [[[0.75 0.75]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.5  0.5 ]\n",
      " [0.75 0.5 ]]\n",
      "p_low_all __str__ = [[0.5       0.5      ]\n",
      " [0.5621765 0.4378235]]\n"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0])\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([1, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    T.printing.Print('alpha')(alpha)\n",
    "    T.printing.Print('beta')(beta)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Trial 0\n",
    "    ## Select TS\n",
    "    p_high0 = T.nnet.softmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('p_high0')(p_high0.flatten())\n",
    "\n",
    "    TS0 = pm.Categorical('TS0', p_high0)\n",
    "#     TS0 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS0 = T.argmax(p_high)[0]\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low0 = T.nnet.softmax(Q_low0[TS0])\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE_high)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE_low)\n",
    "    \n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Select TS\n",
    "    p_high1 = T.nnet.softmax(Q_high1[seasons[1]])\n",
    "    T.printing.Print('p_high1')(p_high1.flatten())\n",
    "\n",
    "    TS1 = pm.Categorical('TS1', p_high1)\n",
    "#     TS1 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS1 = T.argmax(p_high)[1]\n",
    "    T.printing.Print('TS1')(TS1)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low1 = T.nnet.softmax(Q_low1[TS1])\n",
    "    T.printing.Print('p_low1')(p_low1)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[1], TS1\n",
    "    now_low = TS1, aliens[1], actions[1]\n",
    "    \n",
    "    RPE_high = rewards[1] - Q_high1[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[1] - Q_low1[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high2 = T.set_subtensor(Q_high1[now_high],\n",
    "                              Q_high1[now_high] + alpha * RPE_high)\n",
    "    Q_low2 = T.set_subtensor(Q_low1[now_low],\n",
    "                             Q_low1[now_low] + alpha * RPE_low)\n",
    "    T.printing.Print('Q_high2')(Q_high2)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low0[TS0, aliens[0]],\n",
    "                               Q_low1[TS1, aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low_all = T.concatenate([p_low0[aliens[0]],\n",
    "                               p_low1[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('p_low_all')(p_low_all)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low_all, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS agent, softmax update in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha __str__ = 0.5\n",
      "beta __str__ = 1.0\n",
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high0 __str__ = [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS0 __str__ = 0\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = 0.5\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high1 __str__ = [0.5621765 0.4378235]\n",
      "TS1 __str__ = 0\n",
      "p_low1 __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n",
      "RPE_high __str__ = 0.25\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high2 __str__ = [[0.875 0.5  ]\n",
      " [0.5   0.5  ]]\n",
      "Q_low2 __str__ = [[[0.75 0.75]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.5  0.5 ]\n",
      " [0.75 0.5 ]]\n",
      "p_low_all __str__ = [[0.5       0.5      ]\n",
      " [0.5621765 0.4378235]]\n"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0])\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([1, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    T.printing.Print('alpha')(alpha)\n",
    "    T.printing.Print('beta')(beta)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Trial 0\n",
    "    ## Select TS\n",
    "    p_high0 = T.nnet.softmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('p_high0')(p_high0.flatten())\n",
    "\n",
    "    TS0 = pm.Categorical('TS0', p_high0)\n",
    "#     TS0 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS0 = T.argmax(p_high)[0]\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low0 = T.nnet.softmax(Q_low0[TS0])\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE_high)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE_low)\n",
    "    \n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Select TS\n",
    "    p_high1 = T.nnet.softmax(Q_high1[seasons[1]])\n",
    "    T.printing.Print('p_high1')(p_high1.flatten())\n",
    "\n",
    "    TS1 = pm.Categorical('TS1', p_high1)\n",
    "#     TS1 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS1 = T.argmax(p_high)[1]\n",
    "    T.printing.Print('TS1')(TS1)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low1 = T.nnet.softmax(Q_low1[TS1])\n",
    "    T.printing.Print('p_low1')(p_low1)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[1], TS1\n",
    "    now_low = TS1, aliens[1], actions[1]\n",
    "    \n",
    "    RPE_high = rewards[1] - Q_high1[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[1] - Q_low1[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high2 = T.set_subtensor(Q_high1[now_high],\n",
    "                              Q_high1[now_high] + alpha * RPE_high)\n",
    "    Q_low2 = T.set_subtensor(Q_low1[now_low],\n",
    "                             Q_low1[now_low] + alpha * RPE_low)\n",
    "    T.printing.Print('Q_high2')(Q_high2)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low0[TS0, aliens[0]],\n",
    "                               Q_low1[TS1, aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low_all = T.concatenate([p_low0[aliens[0]],\n",
    "                               p_low1[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('p_low_all')(p_low_all)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low_all, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha __str__ = 0.5\n",
      "beta __str__ = 1.0\n",
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high0 __str__ = [0.5 0.5]\n",
      "TS0 __str__ = 0\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RPE_high __str__ = 0.5\n",
      "RPE_low __str__ = [0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2320: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[0][inputs[2:]] = inputs[1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high1 __str__ = [0.5621765 0.4378235]\n",
      "TS1 __str__ = 0\n",
      "p_low1 __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n",
      "RPE_high __str__ = 0.25\n",
      "RPE_low __str__ = [0.5]\n",
      "Q_high2 __str__ = [[0.875 0.5  ]\n",
      " [0.5   0.5  ]]\n",
      "Q_low2 __str__ = [[[0.75 0.75]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.5  0.5 ]\n",
      " [0.75 0.5 ]]\n",
      "p_low_all __str__ = [[0.5       0.5      ]\n",
      " [0.5621765 0.4378235]]\n"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0])\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([1, 1])\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "class CustomTSDist(pm.DiscreteUniform):\n",
    "    def __init__(self, lower, upper, z, *args, **kwargs):\n",
    "        super(CustomTSDist, self).__init__(lower, upper, *args, **kwargs)\n",
    "        self.z = z  # Raw values as inputs for softmax (len = len(TS domain))\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        \n",
    "    def random(self, Q_high, seasons, rewards):\n",
    "        \n",
    "        TSs = T.zeros(len(seasons))\n",
    "        for trial in range(len(seasons)):\n",
    "            p_high = T.nnet.softmax(Q_high[seasons[trial]])\n",
    "            TS = choice(p_high)\n",
    "            Q_high[TS] += alpha_high * (rewards[trial] - Q_high[TS])\n",
    "            TSs[trial] = TS\n",
    "            \n",
    "        return TSs\n",
    "        \n",
    "    def logp(self, value):\n",
    "        upper = self.upper\n",
    "        lower = self.lower\n",
    "        # bound bounds a distribution, takes probability computation as first argument, bounds as 2nd/3rd\n",
    "        p = T.exp(self.z) / T.sum(T.exp(self.z))  # Softmax\n",
    "        return pm.distributions.dist_math.bound(-T.log(p), lower <= value, value <= upper)\n",
    "    \n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    T.printing.Print('alpha')(alpha)\n",
    "    T.printing.Print('beta')(beta)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Set up TS distribution (softmax)\n",
    "    # Trial 0\n",
    "    ## Select TS\n",
    "    p_high0 = T.nnet.softmax(Q_high0[seasons[0]])\n",
    "    TS0 = CustomTSDist('TS0', 0, 1, z=Q_high0[seasons[0]])\n",
    "    T.printing.Print('p_high0')(p_high0.flatten())\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "\n",
    "    ## Calculate action values for this trial\n",
    "    p_low0 = T.nnet.softmax(Q_low0[TS0])\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS, aliens[0], actions[0]\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE_high)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE_low)\n",
    "    \n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Select TS\n",
    "    p_high1 = T.nnet.softmax(Q_high1[seasons[1]])\n",
    "    TS1 = CustomTSDist('TS1', 0, 1, z=Q_high1[seasons[1]])\n",
    "    T.printing.Print('p_high1')(p_high1.flatten())\n",
    "    T.printing.Print('TS1')(TS1)\n",
    "    ## Calculate action values for this trial\n",
    "    p_low1 = T.nnet.softmax(Q_low1[TS1])\n",
    "    T.printing.Print('p_low1')(p_low1)\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[1], TS1\n",
    "    now_low = TS, aliens[1], actions[1]\n",
    "    \n",
    "    RPE_high = rewards[1] - Q_high1[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[1] - Q_low1[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high2 = T.set_subtensor(Q_high1[now_high],\n",
    "                              Q_high1[now_high] + alpha * RPE_high)\n",
    "    Q_low2 = T.set_subtensor(Q_low1[now_low],\n",
    "                             Q_low1[now_low] + alpha * RPE_low)\n",
    "    T.printing.Print('Q_high2')(Q_high2)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low0[TS0, aliens[0]],\n",
    "                               Q_low1[TS1, aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low_all = T.concatenate([p_low0[aliens[0]],\n",
    "                               p_low1[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('p_low_all')(p_low_all)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low_all, observed=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# np.where([True, False, True, False], np.ones(4), np.zeros(4))\n",
    "# np.where([False, True, True], np.array([0, 1, 2]), np.where(np.array([1, 2, 99]))\n",
    "print(3 - np.sum([True, True, True]))  # should return TS 0\n",
    "print(3 - np.sum([False, True, True]))  # should return TS 1\n",
    "print(3 - np.sum([False, False, True]))  # should return TS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.3 1. ]\n",
      " [0.8 0.9 1. ]]\n",
      "[[0.31117788]\n",
      " [0.65785024]]\n",
      "[[False False  True]\n",
      " [ True  True  True]]\n",
      "[2 0]\n"
     ]
    }
   ],
   "source": [
    "p = np.array([[0.1, 0.2, 0.7],\n",
    "              [0.8, 0.1, 0.1]])\n",
    "# print(p)\n",
    "\n",
    "cumsum = np.cumsum(p, axis=1)\n",
    "print(cumsum)\n",
    "\n",
    "rand = np.random.rand(2).reshape((2, 1))\n",
    "print(rand)\n",
    "\n",
    "rand_cumsum = rand < cumsum\n",
    "print(rand_cumsum)\n",
    "\n",
    "choice = 3 - np.sum(rand_cumsum, axis=1)\n",
    "print(choice)\n",
    "\n",
    "# b = np.array([[True, True, True],\n",
    "#               [False, True, True],\n",
    "#               [False, False, True]])\n",
    "# print(b)\n",
    "\n",
    "# a = np.arange(9).reshape((3, 3))\n",
    "# print(a)\n",
    "# print(np.sum(a, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand __str__ = 0.63858724\n",
      "cumsum __str__ = [0.33333334 0.6666667  1.        ]\n",
      "TS __str__ = 1\n",
      "Q_low_sub __str__ = [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_low __str__ = [[0.5 0.5]]\n",
      "RPE_high __str__ = -0.5\n",
      "TS __str__ = [1 2 0 0 2 1]\n",
      "Q_low __str__ = [[[[0.5  0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.5  0.5 ]\n",
      "   [0.5  0.5 ]]]\n",
      "\n",
      "\n",
      " [[[0.5  0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.5  0.75]\n",
      "   [0.5  0.5 ]]]\n",
      "\n",
      "\n",
      " [[[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.5  0.75]\n",
      "   [0.5  0.5 ]]]\n",
      "\n",
      "\n",
      " [[[0.25 0.75]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.5  0.75]\n",
      "   [0.5  0.5 ]]]\n",
      "\n",
      "\n",
      " [[[0.25 0.75]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.5 ]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.75]\n",
      "   [0.5  0.5 ]]]\n",
      "\n",
      "\n",
      " [[[0.25 0.75]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.75]\n",
      "   [0.5  0.5 ]]\n",
      "\n",
      "  [[0.25 0.75]\n",
      "   [0.5  0.5 ]]]]\n",
      "p_low __str__ = [[[0.5       0.5      ]]\n",
      "\n",
      " [[0.5       0.5      ]]\n",
      "\n",
      " [[0.5       0.5      ]]\n",
      "\n",
      " [[0.4378235 0.5621765]]\n",
      "\n",
      " [[0.4378235 0.5621765]]\n",
      "\n",
      " [[0.4378235 0.5621765]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input dimension mis-match. (input[0].shape[1] = 6, input[1].shape[1] = 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-655590278acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m# Select actions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'actions'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_low\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\pymc3\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mtotal_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Name needs to be a string but got: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36mVar\u001b[1;34m(self, name, dist, data, total_size)\u001b[0m\n\u001b[0;32m    836\u001b[0m                 var = ObservedRV(name=name, data=data,\n\u001b[0;32m    837\u001b[0m                                  \u001b[0mdistribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                                  total_size=total_size, model=self)\n\u001b[0m\u001b[0;32m    839\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, type, owner, index, name, data, distribution, total_size, model)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1319\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogp_elemwiset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1320\u001b[0m             \u001b[1;31m# The logp might need scaling in minibatches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m             \u001b[1;31m# This is done in `Factor`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\pymc3\\distributions\\discrete.py\u001b[0m in \u001b[0;36mlogp\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    735\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalue_clip\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msumto1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_repr_latex_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\pymc3\\distributions\\dist_math.py\u001b[0m in \u001b[0;36mbound\u001b[1;34m(logp, *conditions, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0malltrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malltrue_scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malltrue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[0mrequired\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[1;31m# We provided all inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m()\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m             \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\gof\\cc.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m             \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input dimension mis-match. (input[0].shape[1] = 6, input[1].shape[1] = 2)"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0, 0, 0, 0, 0])\n",
    "aliens = np.array([0, 0, 0, 0, 0, 0])\n",
    "actions = np.array([0, 1, 0, 1, 0, 1])\n",
    "rewards = np.array([0, 1, 0, 1, 0, 1])\n",
    "n_trials = 4\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 3\n",
    "\n",
    "seasons = theano.shared(np.asarray(seasons, dtype='int32'))\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    forget = pm.Uniform('forget', lower=0, upper=0.1)\n",
    "    alpha_high = pm.Uniform('alpha_high', lower=0.01, upper=0.2)\n",
    "#     T.printing.Print('alpha')(alpha)\n",
    "#     T.printing.Print('beta')(beta)\n",
    "#     T.printing.Print('forget')(forget)\n",
    "#     T.printing.Print('alpha_high')(alpha_high)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "#     T.printing.Print('Q_high0')(Q_high0)\n",
    "#     T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Set up TS distribution (softmax)\n",
    "    def update_Qs(season, alien, action, reward,\n",
    "                  Q_low, Q_high,\n",
    "                  beta, alpha, alpha_high, forget, n_TS):\n",
    "        \n",
    "        # Select TS\n",
    "        Q_high_sub = Q_high[season]\n",
    "        p_high = T.nnet.softmax(Q_high_sub)\n",
    "#         T.printing.Print('p_high')(p_high)\n",
    "        \n",
    "        rand = rs.uniform()\n",
    "        T.printing.Print('rand')(rand)\n",
    "        \n",
    "        cumsum = T.extra_ops.cumsum(p_high)\n",
    "        T.printing.Print('cumsum')(cumsum)\n",
    "        \n",
    "#         TS = season  # Flat\n",
    "        TS = n_TS - T.sum(rand < cumsum)\n",
    "        T.printing.Print('TS')(TS)\n",
    "\n",
    "        # Calculate action probabilities based on TS\n",
    "        Q_low_sub = Q_low[TS, alien]  # Q_low_sub.shape -> [n_subj, n_actions]\n",
    "        T.printing.Print('Q_low_sub')(Q_low_sub)\n",
    "        p_low = T.nnet.softmax(beta * Q_low_sub)\n",
    "        T.printing.Print('p_low')(p_low)\n",
    "\n",
    "        # Forget Q-values a little bit\n",
    "#         Q_low = (1 - forget) * Q_low + forget * alien_initial_Q\n",
    "        # Q_high = (1 - forget_high) * Q_high + forget_high * alien_initial_Q\n",
    "\n",
    "        # Calculate RPEs & update Q-values\n",
    "        current_trial_high = season, TS\n",
    "        RPE_high = reward - Q_high[current_trial_high]\n",
    "        T.printing.Print('RPE_high')(RPE_high)\n",
    "        Q_high = T.set_subtensor(Q_high[current_trial_high],\n",
    "                                 Q_high[current_trial_high] + alpha_high * RPE_high)\n",
    "\n",
    "        current_trial_low = TS, alien, action\n",
    "        RPE_low = reward - Q_low[current_trial_low]\n",
    "        Q_low = T.set_subtensor(Q_low[current_trial_low],\n",
    "                                Q_low[current_trial_low] + alpha * RPE_low)\n",
    "\n",
    "        return [Q_low, Q_high, TS, p_low]\n",
    "\n",
    "    [Q_low, _, TS, p_low], _ = theano.scan(fn=update_Qs,\n",
    "                                           sequences=[seasons, aliens, actions, rewards],\n",
    "                                           outputs_info=[Q_low0, Q_high0, None, None],\n",
    "                                           non_sequences=[beta, alpha, alpha_high, forget, n_TS])\n",
    "    T.printing.Print('TS')(TS)\n",
    "    T.printing.Print('Q_low')(Q_low)    \n",
    "    T.printing.Print('p_low')(p_low)\n",
    "        \n",
    "    # Select actions    \n",
    "    actions = pm.Categorical('actions', p_low, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom distribution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from theano import function\n",
    "rs = RandomStreams(seed=234)\n",
    "rv_u = rs.uniform()\n",
    "rv_n = rs.normal((2,2))\n",
    "f = function([], rv_u)\n",
    "g = function([], rv_n, no_default_updates=True)    #Not updating rv_n.rng\n",
    "# nearly_zeros = function([], rv_u + rv_u - 2 * rv_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_val0 = f()\n",
    "f_val1 = f()  #different numbers from f_val0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12672381\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(f_val0)\n",
    "print(nearly_zeros())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYMC3",
   "language": "python",
   "name": "pymc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
