{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE __str__ = -0.5\n",
      "Q_low1 __str__ = [[0.25 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "RPE __str__ = 0.5\n",
      "Q_low2 __str__ = [[0.25 0.75]\n",
      " [0.5  0.5 ]]\n",
      "Q_low_all __str__ = [[0.25 0.5 ]\n",
      " [0.25 0.75]]\n",
      "p_low __str__ = [[0.4378235  0.5621765 ]\n",
      " [0.37754068 0.62245935]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "# Data: 4 trials, 2 actions\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([0, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    \n",
    "    # Trial 1\n",
    "    Q_low0 = 0.5 * T.ones([n_aliens, n_actions])  # initialize Q-values for all trials, aliens, & actions to 0.5\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    RPE = rewards[0] - Q_low0[aliens[0], actions[0]]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "    Q_low1 = T.set_subtensor(Q_low0[aliens[0], actions[0]],\n",
    "                             Q_low0[aliens[0], actions[0]] + alpha * RPE)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 2\n",
    "    RPE = rewards[1] - Q_low1[aliens[1], actions[1]]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "    Q_low2 = T.set_subtensor(Q_low1[aliens[1], actions[1]],\n",
    "                             Q_low1[aliens[1], actions[1]] + alpha * RPE)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "    \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low2[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low = T.nnet.softmax(beta * Q_low_all)\n",
    "    T.printing.Print('p_low')(p_low)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple TS agent with argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n",
      "TS0 __str__ = 0\n",
      "Q_low0_sub __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = -0.5\n",
      "RPE_low __str__ = -0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]\n",
      " [0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "p_low __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]\n",
      " [0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    }
   ],
   "source": [
    "# Data: 4 trials, 2 actions\n",
    "seasons = np.array([0, 0, 0, 0])\n",
    "aliens = np.array([0, 0, 1, 1])\n",
    "actions = np.array([0, 1, 0, 1])\n",
    "rewards = np.array([0, 1, 0, 1])\n",
    "\n",
    "n_trials = 4\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Get Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    ## Select TS\n",
    "    TS0 = T.argmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Select action based on TS\n",
    "    Q_low0_sub = Q_low0[TS0]\n",
    "    p_low0 = T.nnet.softmax(Q_low0_sub)\n",
    "    T.printing.Print('Q_low0_sub')(Q_low0_sub)\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs and update Q-values\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE)\n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "#     # Trial 2\n",
    "#     RPE = rewards[1] - Q_low1[aliens[1], actions[1]]  # calculate RPE of the first trial\n",
    "#     T.printing.Print('RPE')(RPE)\n",
    "    \n",
    "#     Q_low2 = T.set_subtensor(Q_low1[aliens[1], actions[1]],\n",
    "#                              Q_low1[aliens[1], actions[1]] + alpha * RPE)\n",
    "#     T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "#     Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low2[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    Q_low_all = T.concatenate([Q_low1[aliens[0]], Q_low1[aliens[0]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low = T.nnet.softmax(beta * Q_low_all)\n",
    "    T.printing.Print('p_low')(p_low)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple TS agent with custom softmax selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a __str__ = [0 1]\n",
      "p __str__ = [0.5 0.5]\n",
      "TS __str__ = [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Print{message='TS', attrs=('__str__',), global_fn=<function _print_fn at 0x000001519417A9D8>}.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "rs = RandomStreams()\n",
    "# theano.sandbox.rng_mrg.MRG_RandomStreams.choice(size=1, a=None, replace=True, p=None, ndim=None, dtype='int64', nstreams=None, **kwargs)\n",
    "\n",
    "a = T.arange(2)\n",
    "p = T.as_tensor_variable(np.array([0.5, 0.5]))\n",
    "T.printing.Print('a')(a)\n",
    "T.printing.Print('p')(p)\n",
    "TS = rs.choice(size=[1], a=a, p=p)\n",
    "T.printing.Print('TS')(TS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha __str__ = 0.5\n",
      "beta __str__ = 1.0\n",
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high0 __str__ = [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS0 __str__ = 0\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = 0.5\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high1 __str__ = [0.5621765 0.4378235]\n",
      "TS1 __str__ = 0\n",
      "p_low1 __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n",
      "RPE_high __str__ = 0.25\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high2 __str__ = [[0.875 0.5  ]\n",
      " [0.5   0.5  ]]\n",
      "Q_low2 __str__ = [[[0.75 0.75]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.5  0.5 ]\n",
      " [0.75 0.5 ]]\n",
      "p_low_all __str__ = [[0.5       0.5      ]\n",
      " [0.5621765 0.4378235]]\n"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0])\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([1, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    T.printing.Print('alpha')(alpha)\n",
    "    T.printing.Print('beta')(beta)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Trial 0\n",
    "    ## Select TS\n",
    "    p_high0 = T.nnet.softmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('p_high0')(p_high0.flatten())\n",
    "\n",
    "    TS0 = pm.Categorical('TS0', p_high0)\n",
    "#     TS0 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS0 = T.argmax(p_high)[0]\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low0 = T.nnet.softmax(Q_low0[TS0])\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE_high)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE_low)\n",
    "    \n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Select TS\n",
    "    p_high1 = T.nnet.softmax(Q_high1[seasons[1]])\n",
    "    T.printing.Print('p_high1')(p_high1.flatten())\n",
    "\n",
    "    TS1 = pm.Categorical('TS1', p_high1)\n",
    "#     TS1 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS1 = T.argmax(p_high)[1]\n",
    "    T.printing.Print('TS1')(TS1)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low1 = T.nnet.softmax(Q_low1[TS1])\n",
    "    T.printing.Print('p_low1')(p_low1)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[1], TS1\n",
    "    now_low = TS1, aliens[1], actions[1]\n",
    "    \n",
    "    RPE_high = rewards[1] - Q_high1[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[1] - Q_low1[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high2 = T.set_subtensor(Q_high1[now_high],\n",
    "                              Q_high1[now_high] + alpha * RPE_high)\n",
    "    Q_low2 = T.set_subtensor(Q_low1[now_low],\n",
    "                             Q_low1[now_low] + alpha * RPE_low)\n",
    "    T.printing.Print('Q_high2')(Q_high2)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low0[TS0, aliens[0]],\n",
    "                               Q_low1[TS1, aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low_all = T.concatenate([p_low0[aliens[0]],\n",
    "                               p_low1[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('p_low_all')(p_low_all)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low_all, observed=actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS agent, softmax update in loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha __str__ = 0.5\n",
      "beta __str__ = 1.0\n",
      "Q_high0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "Q_low0 __str__ = [[[0.5 0.5]\n",
      "  [0.5 0.5]]\n",
      "\n",
      " [[0.5 0.5]\n",
      "  [0.5 0.5]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high0 __str__ = [0.5 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\theano\\tensor\\subtensor.py:2190: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  rval = inputs[0].__getitem__(inputs[1:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS0 __str__ = 0\n",
      "p_low0 __str__ = [[0.5 0.5]\n",
      " [0.5 0.5]]\n",
      "RPE_high __str__ = 0.5\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high1 __str__ = [[0.75 0.5 ]\n",
      " [0.5  0.5 ]]\n",
      "Q_low1 __str__ = [[[0.75 0.5 ]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\envs\\PYMC3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_high1 __str__ = [0.5621765 0.4378235]\n",
      "TS1 __str__ = 0\n",
      "p_low1 __str__ = [[0.5621765 0.4378235]\n",
      " [0.5       0.5      ]]\n",
      "RPE_high __str__ = 0.25\n",
      "RPE_low __str__ = 0.5\n",
      "Q_high2 __str__ = [[0.875 0.5  ]\n",
      " [0.5   0.5  ]]\n",
      "Q_low2 __str__ = [[[0.75 0.75]\n",
      "  [0.5  0.5 ]]\n",
      "\n",
      " [[0.5  0.5 ]\n",
      "  [0.5  0.5 ]]]\n",
      "Q_low_all __str__ = [[0.5  0.5 ]\n",
      " [0.75 0.5 ]]\n",
      "p_low_all __str__ = [[0.5       0.5      ]\n",
      " [0.5621765 0.4378235]]\n"
     ]
    }
   ],
   "source": [
    "# Data: 2 trials, 2 actions\n",
    "seasons = np.array([0, 0])\n",
    "aliens = np.array([0, 0])\n",
    "actions = np.array([0, 1])\n",
    "rewards = np.array([1, 1])\n",
    "\n",
    "n_trials = 2\n",
    "n_aliens = 2\n",
    "n_actions = 2\n",
    "n_seasons = 2\n",
    "n_TS = 2\n",
    "\n",
    "aliens = theano.shared(np.asarray(aliens, dtype='int32'))\n",
    "actions = theano.shared(np.asarray(actions, dtype='int32'))\n",
    "rewards = theano.shared(np.asarray(rewards, dtype='int32'))\n",
    "\n",
    "with pm.Model() as model:\n",
    "    \n",
    "    # RL parameters\n",
    "    alpha = pm.Uniform('alpha', lower=0, upper=1)\n",
    "    beta = pm.Bound(pm.Normal, lower=0)('beta', mu=1, sd=5)\n",
    "    T.printing.Print('alpha')(alpha)\n",
    "    T.printing.Print('beta')(beta)\n",
    "    \n",
    "    # Initial Q-values\n",
    "    Q_high0 = 0.5 * T.ones([n_seasons, n_TS])  # Q-values linking seasons to TS\n",
    "    Q_low0 = 0.5 * T.ones([n_TS, n_aliens, n_actions])  # Q-values linking TS & aliens to actions\n",
    "    T.printing.Print('Q_high0')(Q_high0)\n",
    "    T.printing.Print('Q_low0')(Q_low0)\n",
    "    \n",
    "    # Trial 0\n",
    "    ## Select TS\n",
    "    p_high0 = T.nnet.softmax(Q_high0[seasons[0]])\n",
    "    T.printing.Print('p_high0')(p_high0.flatten())\n",
    "\n",
    "    TS0 = pm.Categorical('TS0', p_high0)\n",
    "#     TS0 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS0 = T.argmax(p_high)[0]\n",
    "    T.printing.Print('TS0')(TS0)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low0 = T.nnet.softmax(Q_low0[TS0])\n",
    "    T.printing.Print('p_low0')(p_low0)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[0], TS0\n",
    "    now_low = TS0, aliens[0], actions[0]\n",
    "\n",
    "    RPE_high = rewards[0] - Q_high0[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[0] - Q_low0[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high1 = T.set_subtensor(Q_high0[now_high],\n",
    "                              Q_high0[now_high] + alpha * RPE_high)\n",
    "    Q_low1 = T.set_subtensor(Q_low0[now_low],\n",
    "                             Q_low0[now_low] + alpha * RPE_low)\n",
    "    \n",
    "    T.printing.Print('Q_high1')(Q_high1)\n",
    "    T.printing.Print('Q_low1')(Q_low1)\n",
    "    \n",
    "    # Trial 1\n",
    "    ## Select TS\n",
    "    p_high1 = T.nnet.softmax(Q_high1[seasons[1]])\n",
    "    T.printing.Print('p_high1')(p_high1.flatten())\n",
    "\n",
    "    TS1 = pm.Categorical('TS1', p_high1)\n",
    "#     TS1 = rs.choice(size=[1], a=T.arange(n_TS), p=p_high.flatten())\n",
    "#     TS1 = T.argmax(p_high)[1]\n",
    "    T.printing.Print('TS1')(TS1)\n",
    "    \n",
    "    ## Calculate action values for this trial\n",
    "    p_low1 = T.nnet.softmax(Q_low1[TS1])\n",
    "    T.printing.Print('p_low1')(p_low1)\n",
    "\n",
    "    ## Calculate RPEs\n",
    "    now_high = seasons[1], TS1\n",
    "    now_low = TS1, aliens[1], actions[1]\n",
    "    \n",
    "    RPE_high = rewards[1] - Q_high1[now_high]  # calculate RPE of the first trial\n",
    "    RPE_low = rewards[1] - Q_low1[now_low]  # calculate RPE of the first trial\n",
    "    \n",
    "    T.printing.Print('RPE_high')(RPE_high)\n",
    "    T.printing.Print('RPE_low')(RPE_low)\n",
    "    \n",
    "    ## Update Q-values\n",
    "    Q_high2 = T.set_subtensor(Q_high1[now_high],\n",
    "                              Q_high1[now_high] + alpha * RPE_high)\n",
    "    Q_low2 = T.set_subtensor(Q_low1[now_low],\n",
    "                             Q_low1[now_low] + alpha * RPE_low)\n",
    "    T.printing.Print('Q_high2')(Q_high2)\n",
    "    T.printing.Print('Q_low2')(Q_low2)\n",
    "        \n",
    "    # Select actions\n",
    "    Q_low_all = T.concatenate([Q_low0[TS0, aliens[0]],\n",
    "                               Q_low1[TS1, aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('Q_low_all')(Q_low_all)\n",
    "    \n",
    "    p_low_all = T.concatenate([p_low0[aliens[0]],\n",
    "                               p_low1[aliens[1]]]).reshape((n_trials, n_actions))\n",
    "    T.printing.Print('p_low_all')(p_low_all)\n",
    "    \n",
    "    actions = pm.Categorical('actions', p_low_all, observed=actions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYMC3",
   "language": "python",
   "name": "pymc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
